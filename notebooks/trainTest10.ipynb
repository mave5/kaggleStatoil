{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 20.0% of memory, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#norm_type='zeroMeanUnitStd'\n",
    "#norm_type='minus1plus1'\n",
    "norm_type=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        #band_3 = band_1 / band_2\n",
    "\n",
    "        # Rescale\n",
    "        band_1 = (band_1 - band_1.min()) / (band_1.max() - band_1.min())\n",
    "        band_2 = (band_2 - band_2.min()) / (band_2.max() - band_2.min())\n",
    "        #b = (band_3 - band_3.min()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        b1b2 = np.dstack((band_1, band_2)).astype('float32')\n",
    "        images.append(b1b2)\n",
    "    images=np.array(images,'float32')\n",
    "    images=np.transpose(images,(0,3,1,2))\n",
    "    return images\n",
    "\n",
    "def get_scaled_imgs(df):\n",
    "    \"\"\"\n",
    "    basic function for reshaping and rescaling data as images\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "        \n",
    "        # Rescale\n",
    "        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n",
    "        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        imgs.append(np.dstack((a, b, c)))\n",
    "    imgs=np.array(imgs,'float32')\n",
    "    imgs=np.transpose(imgs,(0,3,1,2))\n",
    "        \n",
    "    return np.array(imgs)    \n",
    "\n",
    "\n",
    "def array_stats(X):\n",
    "    X=np.asarray(X)\n",
    "    print ('array shape and type: ',X.shape, X.dtype)\n",
    "    #print 'min: %.3f, max:%.3f, avg: %.3f, std:%.3f' %(np.min(X),np.max(X),np.mean(X),np.std(X))\n",
    "    print ('min: {}, max: {}, avg: {:.3}, std:{:.3}'.format( np.min(X),np.max(X),np.mean(X),np.std(X)))\n",
    "    \n",
    "    \n",
    "def preprocess(X,xnormType=None):\n",
    "    if xnormType=='minus1plus1':\n",
    "        X=X.astype('float32')\n",
    "        X/=np.max(X)\n",
    "        X-=0.5\n",
    "        X=X*2\n",
    "    elif xnormType=='zeroMeanUnitStd':\n",
    "        X=X.astype('float32')\n",
    "        # we do this per channel\n",
    "        for c in range(X.shape[1]):\n",
    "            X[:,c]-=np.mean(X[:,c])\n",
    "            stdXc=np.std(X[:,c])\n",
    "            if stdXc>0.0:\n",
    "                X[:,c]/=stdXc\n",
    "    else:\n",
    "        print('no normalization!')\n",
    "    return X\n",
    "    \n",
    "# train test model\n",
    "def train_test_model(X_train,y_train,X_test,y_test,params_train):\n",
    "    foldnm=params_train['foldnm']  \n",
    "    pre_train=params_train['pre_train'] \n",
    "    batch_size=params_train['batch_size'] \n",
    "    augmentation=params_train['augmentation'] \n",
    "    path2weights=params_train['path2weights'] \n",
    "    print('batch_size: %s, Augmentation: %s' %(batch_size,augmentation))\n",
    "    \n",
    "    print 'fold %s training in progress ...' %foldnm\n",
    "    # load last weights\n",
    "    if pre_train== True:\n",
    "        if  os.path.exists(path2weights):\n",
    "            model.load_weights(path2weights)\n",
    "            print 'previous weights loaded!'\n",
    "        else:\n",
    "            raise IOError('weights does not exist!!!')\n",
    "    else:\n",
    "        if  os.path.exists(path2weights):\n",
    "            model.load_weights(path2weights)\n",
    "            print (path2weights)\n",
    "            print ('previous weights loaded!')\n",
    "            train_status='previous weights'\n",
    "            return train_status\n",
    "    \n",
    "    # path to csv file to save scores\n",
    "    path2scorescsv = weightfolder+'/scores.csv'\n",
    "    first_row = 'train,test'\n",
    "    with open(path2scorescsv, 'w+') as f:\n",
    "        f.write(first_row + '\\n')\n",
    "           \n",
    "    # Fit the model\n",
    "    start_time=time.time()\n",
    "    scores_test=[]\n",
    "    scores_train=[]\n",
    "    if params_train['loss']=='dice': \n",
    "        best_score = 0\n",
    "        previous_score = 0\n",
    "    else:\n",
    "        best_score = 1e6\n",
    "        previous_score = 1e6\n",
    "    patience = 0\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    #y_train = np_utils.to_categorical(y_train, nb_outputs)\n",
    "    #y_test = np_utils.to_categorical(y_test, nb_outputs)\n",
    "    \n",
    "    \n",
    "    for epoch in range(params_train['nbepoch']):\n",
    "    \n",
    "        print ('epoch: %s,  Current Learning Rate: %.1e' %(epoch,model.optimizer.lr.get_value()))\n",
    "        #seed = np.random.randint(0, 999999)\n",
    "    \n",
    "        if augmentation:\n",
    "            batches=0\n",
    "            bs=len(X_train)#batch_size*10\n",
    "            for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=bs,shuffle=True):\n",
    "                X_batch=preprocess(X_batch,norm_type)\n",
    "                hist=model.fit(X_batch, y_batch, batch_size=batch_size,nb_epoch=1, verbose=0)\n",
    "                batches += 1\n",
    "                if batches >= len(X_train) / bs:\n",
    "                    # we need to break the loop by hand because\n",
    "                    # the generator loops indefinitely\n",
    "                    break\n",
    "        else:\n",
    "            hist=model.fit(preprocess(X_train,norm_type)[:,:,np.newaxis], y_train, batch_size=batch_size,nb_epoch=1, verbose=0)\n",
    "            \n",
    "        # evaluate on test and train data\n",
    "        score_test=model.evaluate(preprocess(X_test,norm_type),y_test,verbose=0)\n",
    "        score_train=np.mean(hist.history['loss'])\n",
    "       \n",
    "        print ('score_train: %s, score_test: %s' %(score_train,score_test))\n",
    "        scores_test=np.append(scores_test,score_test)\n",
    "        scores_train=np.append(scores_train,score_train)    \n",
    "\n",
    "        # check for improvement    \n",
    "        if (score_test<=best_score):\n",
    "            print (\"!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\") \n",
    "            best_score = score_test\n",
    "            patience = 0\n",
    "            model.save_weights(path2weights)  \n",
    "            model.save(weightfolder+'/model.h5')\n",
    "            \n",
    "        # learning rate schedule\n",
    "        if score_test>previous_score:\n",
    "            #print \"Incrementing Patience.\"\n",
    "            patience += 1\n",
    "\n",
    "        # learning rate schedule                \n",
    "        if patience == params_train['max_patience']:\n",
    "            params_train['learning_rate'] = params_train['learning_rate']/2\n",
    "            print (\"Upating Current Learning Rate to: \", params_train['learning_rate'])\n",
    "            model.optimizer.lr.set_value(params_train['learning_rate'])\n",
    "            print (\"Loading the best weights again. best_score: \",best_score)\n",
    "            model.load_weights(path2weights)\n",
    "            patience = 0\n",
    "        \n",
    "        # save current test score\n",
    "        previous_score = score_test    \n",
    "        \n",
    "        # store scores into csv file\n",
    "        with open(path2scorescsv, 'a') as f:\n",
    "            string = str([score_train,score_test])\n",
    "            f.write(string + '\\n')\n",
    "           \n",
    "    \n",
    "    print ('model was trained!')\n",
    "    elapsed_time=(time.time()-start_time)/60\n",
    "    print ('elapsed time: %d  mins' %elapsed_time)      \n",
    "\n",
    "    # train test progress plots\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(scores_test)\n",
    "    plt.plot(scores_train)\n",
    "    plt.title('train-validation progress',fontsize=20)\n",
    "    plt.legend(('test','train'),fontsize=20)\n",
    "    plt.xlabel('epochs',fontsize=20)\n",
    "    plt.ylabel('loss',fontsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(weightfolder+'/train_val_progress.png')\n",
    "    #plt.show()\n",
    "    \n",
    "    print 'training completed!'\n",
    "    train_status='completed!'\n",
    "    return train_status     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('array shape and type: ', (1604, 3, 75, 75), dtype('float32'))\n",
      "min: -0.727469801903, max: 0.85425567627, avg: 7.05e-12, std:0.0965\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_json('../data/train.json')\n",
    "#X=get_images(train)\n",
    "X=get_scaled_imgs(train)\n",
    "array_stats(X)\n",
    "\n",
    "# labels\n",
    "#y = to_categorical(train.is_iceberg.values,nb_classes=2)\n",
    "y = train.is_iceberg.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADDCAYAAABJYEAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f902081ba50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n1=np.random.randint(len(X))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X[n1,0],cmap='gray');\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(X[n1,1],cmap='gray');\n",
    "plt.title(y[n1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mra/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/mra/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/mra/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3, 75, 75)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 8, 73, 73)     224         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 8, 73, 73)     0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_1 (LeakyReLU)          (None, 8, 73, 73)     0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 8, 36, 36)     0           leakyrelu_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 16, 34, 34)    1168        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 16, 34, 34)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_2 (LeakyReLU)          (None, 16, 34, 34)    0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 16, 17, 17)    0           leakyrelu_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 32, 15, 15)    4640        maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 32, 15, 15)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_3 (LeakyReLU)          (None, 32, 15, 15)    0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 32, 7, 7)      0           leakyrelu_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 64, 5, 5)      18496       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 64, 5, 5)      0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_4 (LeakyReLU)          (None, 64, 5, 5)      0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 64, 2, 2)      0           leakyrelu_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 256)           0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           131584      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           131328      dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 256)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             257         dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 287697\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D,Dropout\n",
    "from keras.layers import Activation,Reshape,Permute,Flatten,Dense\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import RMSprop, Adam,Nadam\n",
    "from keras.layers import GlobalAveragePooling1D,AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.advanced_activations import ELU,PReLU,LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def conv_block(x_input, num_filters,pool=True,norm=False,drop_rate=0.0,border_mode='valid',stride=1):\n",
    "    x1 = Convolution2D(num_filters,3,3,subsample=(stride,stride),border_mode=border_mode,W_regularizer=l2(1e-4))(x_input)\n",
    "    if norm:\n",
    "        x1 = BatchNormalization(mode=2,axis=1)(x1)\n",
    "        \n",
    "    if drop_rate > 0.0:\n",
    "        #x1 = GaussianDropout(drop_rate)(x1)\n",
    "        x1 = Dropout(drop_rate)(x1)\n",
    "\n",
    "    x1 = LeakyReLU(.1)(x1)\n",
    "    if pool:\n",
    "        x1 = MaxPooling2D()(x1)\n",
    "    x_out = x1\n",
    "    return x_out\n",
    "\n",
    "\n",
    "def modelCnn(params):\n",
    "    # input format: batch_size*timesteps*z*h*w    \n",
    "    h=params['h']\n",
    "    w=params['w']\n",
    "    z=params['z']\n",
    "    timesteps=params['timesteps']    \n",
    "    lr=params['learning_rate']\n",
    "    nb_output=params['nb_outputs']\n",
    "    loss=params['loss']\n",
    "    C=params['init_filters']\n",
    "    border_mode=params['border_mode']\n",
    "    base_display=params['base_display']\n",
    "    stride=params['stride']\n",
    "    dropOutRate=params['dropOutRate']\n",
    "    optimizer=params['optimizer']\n",
    "    kS=params['kernelSize']\n",
    "    kI=params['kernelInit']\n",
    "    bnEnable=params['batchNormEnable']\n",
    "    iF=params['init_filters']\n",
    "    \n",
    "    xin = Input((z,h, w))\n",
    "    x1 = conv_block(xin,C,norm=bnEnable,stride=stride,pool=True,drop_rate=dropOutRate,border_mode=border_mode) \n",
    "    x1_merged=x1\n",
    "\n",
    "    x2_1 = conv_block(x1_merged,2*C,norm=bnEnable,pool=True,drop_rate=dropOutRate,border_mode=border_mode) \n",
    "    x2_merged=x2_1\n",
    "\n",
    "    #by branching we reduce the #params\n",
    "    x3_1 = conv_block(x2_merged,4*C,norm=bnEnable,pool=True,drop_rate=dropOutRate,border_mode=border_mode) \n",
    "    x3_merged=x3_1\n",
    "\n",
    "    x4_1 = conv_block(x3_merged,8*C,norm=bnEnable,pool=True,drop_rate=dropOutRate,border_mode=border_mode)\n",
    "    x4_merged=x4_1\n",
    "\n",
    "    # last layer of encoding    \n",
    "    x=Flatten() (x4_1)\n",
    "    x=Dense(512,activation='relu')(x)    \n",
    "    x=Dropout(dropOutRate)(x)\n",
    "\n",
    "    x=Dense(256,activation='relu')(x)    \n",
    "    x=Dropout(dropOutRate)(x)\n",
    "   \n",
    "    x=Dense(nb_output, activation='sigmoid',W_regularizer=l2(1e-4))(x)\n",
    "    \n",
    "    model = Model(input=xin, output=x)\n",
    "    \n",
    "    \n",
    "    if optimizer=='RMSprop':\n",
    "        optimizer = RMSprop(lr)\n",
    "    elif optimizer=='Adam':       \n",
    "        optimizer = Adam(lr)\n",
    "    elif optimizer=='Nadam':       \n",
    "        optimizer = Nadam(lr,clipvalue=1.0)        \n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "# random data generator\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.10,\n",
    "        height_shift_range=0.10,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.10,\n",
    "        channel_shift_range=0.0,\n",
    "        fill_mode='constant',\n",
    "        cval=0.0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        dim_ordering='th') \n",
    "\n",
    "\n",
    "_,z,h,w=X.shape\n",
    "# training params\n",
    "params_train={\n",
    "    'h': h,\n",
    "    'w': w,\n",
    "    'z': z,\n",
    "    'timesteps':None,\n",
    "    'c':1,           \n",
    "    'learning_rate': 3e-4,\n",
    "    #'optimizer': 'Adam',\n",
    "    'optimizer': 'Nadam',\n",
    "    #'loss': 'categorical_crossentropy',\n",
    "    'loss': 'binary_crossentropy',\n",
    "    #'loss': 'mean_squared_error',\n",
    "    'nbepoch': 500,\n",
    "    'nb_outputs': 1,\n",
    "    'init_filters': 8,    \n",
    "    'max_patience': 30,\n",
    "    'stride': 1,\n",
    "    'fully_connected': False,\n",
    "    'output_activation': 'sigmoid',\n",
    "    'border_mode':'valid',\n",
    "    'base_display': True,\n",
    "    'dropOutRate': 0.2,\n",
    "    'pre_train': False,\n",
    "    'foldnm':1,\n",
    "    'kernelSize':3,\n",
    "    'kernelInit':'glorot_uniform',\n",
    "    'batchNormEnable': False,\n",
    "    'batch_size': 32,\n",
    "    'augmentation': True,\n",
    "    'path2weights': None,\n",
    "}    \n",
    "\n",
    "\n",
    "model=modelCnn(params_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get current notebook name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%javascript\n",
    "#var kernel = IPython.notebook.kernel;\n",
    "#var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "#var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "#kernel.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait ...\n",
      "fold 1\n",
      "('array shape and type: ', (1443, 3, 75, 75), dtype('float32'))\n",
      "min: -0.727469801903, max: 0.85425567627, avg: -1.78e-11, std:0.0964\n",
      "('array shape and type: ', (1443,), dtype('int64'))\n",
      "min: 0, max: 1, avg: 0.456, std:0.498\n",
      "('array shape and type: ', (161, 3, 75, 75), dtype('float32'))\n",
      "min: -0.682733356953, max: 0.838276922703, avg: -4.49e-11, std:0.097\n",
      "('array shape and type: ', (161,), dtype('int64'))\n",
      "min: 0, max: 1, avg: 0.59, std:0.492\n",
      "------------------------------\n",
      "experiment: trainTest10_hw_75by75_initfilts_8\n",
      "weights folder created\n",
      "batch_size: 32, Augmentation: True\n",
      "fold 1 training in progress ...\n",
      "./output/weights/trainTest10_hw_75by75_initfilts_8/fold1/weights.hdf5\n",
      "previous weights loaded!\n",
      "./output/weights/trainTest10_hw_75by75_initfilts_8/fold1/weights.hdf5 loaded!\n",
      "no normalization!\n",
      "score_test: 0.69048\n",
      "------------------------------\n",
      "fold 2\n",
      "('array shape and type: ', (1443, 3, 75, 75), dtype('float32'))\n",
      "min: -0.727469801903, max: 0.85425567627, avg: -1.18e-11, std:0.0963\n",
      "('array shape and type: ', (1443,), dtype('int64'))\n",
      "min: 0, max: 1, avg: 0.457, std:0.498\n",
      "('array shape and type: ', (161, 3, 75, 75), dtype('float32'))\n",
      "min: -0.68390160799, max: 0.827781319618, avg: 4.21e-11, std:0.098\n",
      "('array shape and type: ', (161,), dtype('int64'))\n",
      "min: 0, max: 1, avg: 0.584, std:0.493\n",
      "------------------------------\n",
      "experiment: trainTest10_hw_75by75_initfilts_8\n",
      "weights folder created\n",
      "batch_size: 32, Augmentation: True\n",
      "fold 2 training in progress ...\n",
      "epoch: 0,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.686848097887, score_test: 0.698163877178\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 1,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.633697225497, score_test: 0.800131472556\n",
      "epoch: 2,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.555400875919, score_test: 0.551642262047\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 3,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.492447694514, score_test: 0.579207819325\n",
      "epoch: 4,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.45460390582, score_test: 0.497533920481\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 5,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.413347848137, score_test: 0.470043752261\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 6,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.400404715809, score_test: 0.351152494376\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 7,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.386371672876, score_test: 0.387339181527\n",
      "epoch: 8,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.365724125548, score_test: 0.351458704608\n",
      "epoch: 9,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.359358093347, score_test: 0.487882098056\n",
      "epoch: 10,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.365536432752, score_test: 0.337936542986\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 11,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.368141154748, score_test: 0.376337571602\n",
      "epoch: 12,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.360805474126, score_test: 0.332098081274\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 13,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.353285453651, score_test: 0.325259282919\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 14,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.342194067878, score_test: 0.326192873993\n",
      "epoch: 15,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.338881734668, score_test: 0.324757265077\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 16,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.337666949793, score_test: 0.328683548109\n",
      "epoch: 17,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.332624104811, score_test: 0.373310750402\n",
      "epoch: 18,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.327954516832, score_test: 0.332396603516\n",
      "epoch: 19,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.3073105327, score_test: 0.324247922129\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 20,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.322712849895, score_test: 0.295457246453\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 21,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.321874873327, score_test: 0.312202026188\n",
      "epoch: 22,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.330426712521, score_test: 0.450088365993\n",
      "epoch: 23,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.318136913479, score_test: 0.31004746216\n",
      "epoch: 24,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.330639964929, score_test: 0.320747640609\n",
      "epoch: 25,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.32165189297, score_test: 0.294017305679\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 26,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.317956893193, score_test: 0.316755300665\n",
      "epoch: 27,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.317065591851, score_test: 0.285702448986\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 28,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.306702974639, score_test: 0.311968251889\n",
      "epoch: 29,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.311900080242, score_test: 0.350808696931\n",
      "epoch: 30,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.305598766541, score_test: 0.291646872213\n",
      "epoch: 31,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.309283702347, score_test: 0.304510000237\n",
      "epoch: 32,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.30910047358, score_test: 0.28048168375\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 33,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.297345213711, score_test: 0.347708691577\n",
      "epoch: 34,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.30228461194, score_test: 0.281355347091\n",
      "epoch: 35,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.30744194179, score_test: 0.317285898934\n",
      "epoch: 36,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.302522792596, score_test: 0.31348724057\n",
      "epoch: 37,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.31140733651, score_test: 0.28551988262\n",
      "epoch: 38,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.3008966265, score_test: 0.305524638328\n",
      "epoch: 39,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.294091985657, score_test: 0.280277351878\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 40,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.301114356237, score_test: 0.343259062109\n",
      "epoch: 41,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.30716959417, score_test: 0.300739730396\n",
      "epoch: 42,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.291198952282, score_test: 0.348905471634\n",
      "epoch: 43,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.288501894111, score_test: 0.275717377015\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 44,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.289017322075, score_test: 0.27970598999\n",
      "epoch: 45,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.302737080258, score_test: 0.328409223777\n",
      "epoch: 46,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.300495063606, score_test: 0.280696990038\n",
      "epoch: 47,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.297838575955, score_test: 0.273388608689\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 48,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.305344339514, score_test: 0.27597463006\n",
      "epoch: 49,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.286931421615, score_test: 0.277626386456\n",
      "epoch: 50,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.292078486238, score_test: 0.276492175478\n",
      "epoch: 51,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.282520784864, score_test: 0.268844334814\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 52,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.276692215346, score_test: 0.2661290388\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 53,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.294278027878, score_test: 0.264595561424\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 54,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.275282601996, score_test: 0.250164186246\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 55,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.282144375688, score_test: 0.283533150365\n",
      "epoch: 56,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.287349640993, score_test: 0.260135266583\n",
      "epoch: 57,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.278832944086, score_test: 0.265677565026\n",
      "epoch: 58,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.282451842489, score_test: 0.262998395825\n",
      "epoch: 59,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.271539868139, score_test: 0.252364523871\n",
      "epoch: 60,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.265646101614, score_test: 0.244232522081\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 61,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.273296491272, score_test: 0.317302910345\n",
      "epoch: 62,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.27713473387, score_test: 0.241574172139\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 63,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.272275119875, score_test: 0.270435656774\n",
      "epoch: 64,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.278101374262, score_test: 0.263021154989\n",
      "epoch: 65,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.285329024204, score_test: 0.297450128249\n",
      "epoch: 66,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.274001582321, score_test: 0.262858282289\n",
      "epoch: 67,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.258664317698, score_test: 0.24489292308\n",
      "epoch: 68,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.275379364555, score_test: 0.33793593684\n",
      "epoch: 69,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.275841130265, score_test: 0.26419067915\n",
      "epoch: 70,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.264575843783, score_test: 0.258515100371\n",
      "epoch: 71,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.280273676956, score_test: 0.246734737448\n",
      "epoch: 72,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.280018219622, score_test: 0.304096221253\n",
      "epoch: 73,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.290434683053, score_test: 0.258834729237\n",
      "epoch: 74,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.263863195366, score_test: 0.256266714623\n",
      "epoch: 75,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.272408222283, score_test: 0.244299376603\n",
      "epoch: 76,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.270167389065, score_test: 0.276003646115\n",
      "epoch: 77,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.282830729038, score_test: 0.255719876946\n",
      "epoch: 78,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.276266293152, score_test: 0.327888575307\n",
      "epoch: 79,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.271599744736, score_test: 0.257176134064\n",
      "epoch: 80,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.279450991711, score_test: 0.254689265482\n",
      "epoch: 81,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.266462999834, score_test: 0.3861211505\n",
      "epoch: 82,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.280694932379, score_test: 0.245812998657\n",
      "epoch: 83,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.263044974557, score_test: 0.303717792451\n",
      "epoch: 84,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.267327511499, score_test: 0.246776350409\n",
      "epoch: 85,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.261500204634, score_test: 0.269218738243\n",
      "epoch: 86,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.26638218762, score_test: 0.245333446433\n",
      "epoch: 87,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.246345271925, score_test: 0.236020270642\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 88,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.264686912944, score_test: 0.257050847554\n",
      "epoch: 89,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.275904168437, score_test: 0.295791562901\n",
      "epoch: 90,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.254287918703, score_test: 0.236577390791\n",
      "epoch: 91,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.258059470379, score_test: 0.243332970679\n",
      "epoch: 92,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.265879426867, score_test: 0.251618738072\n",
      "epoch: 93,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.261289347761, score_test: 0.238370259009\n",
      "epoch: 94,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.253637463794, score_test: 0.235960039142\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 95,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.269208646603, score_test: 0.255215524794\n",
      "epoch: 96,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.251392429187, score_test: 0.267627517583\n",
      "epoch: 97,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.245947348652, score_test: 0.230404981962\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 98,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.255827177835, score_test: 0.274258046023\n",
      "epoch: 99,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.249344206035, score_test: 0.240257736365\n",
      "epoch: 100,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.253837355654, score_test: 0.260177527919\n",
      "epoch: 101,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.244886497884, score_test: 0.23212869824\n",
      "epoch: 102,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.260408814447, score_test: 0.236089366124\n",
      "epoch: 103,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.262749209817, score_test: 0.23031638565\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 104,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.242564481823, score_test: 0.245160892675\n",
      "epoch: 105,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.265817159138, score_test: 0.249683251338\n",
      "epoch: 106,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.252012315737, score_test: 0.230749648978\n",
      "epoch: 107,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.24933763089, score_test: 0.258998849678\n",
      "epoch: 108,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.249797850496, score_test: 0.278797844552\n",
      "epoch: 109,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.255774003854, score_test: 0.243198154668\n",
      "epoch: 110,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.251634132367, score_test: 0.25627907509\n",
      "epoch: 111,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.251466278475, score_test: 0.275707815375\n",
      "epoch: 112,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.255679333238, score_test: 0.227107657617\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 113,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.244400102896, score_test: 0.267824151131\n",
      "epoch: 114,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.262239030311, score_test: 0.276006581435\n",
      "epoch: 115,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.26068907442, score_test: 0.233184934125\n",
      "epoch: 116,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.243875730762, score_test: 0.218989276391\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 117,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.248658193673, score_test: 0.247726495152\n",
      "epoch: 118,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.254138283674, score_test: 0.287517401234\n",
      "epoch: 119,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.25135341329, score_test: 0.225946337193\n",
      "epoch: 120,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.242902019152, score_test: 0.242423911388\n",
      "epoch: 121,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.245284076679, score_test: 0.218954271874\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 122,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.245005045615, score_test: 0.234364838877\n",
      "epoch: 123,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.248612559774, score_test: 0.231038103031\n",
      "epoch: 124,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.249165054449, score_test: 0.233367607414\n",
      "epoch: 125,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.240428300901, score_test: 0.322504964489\n",
      "epoch: 126,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.249011433814, score_test: 0.296455279502\n",
      "epoch: 127,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.258658077168, score_test: 0.227028931358\n",
      "epoch: 128,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.254272970871, score_test: 0.250722448856\n",
      "epoch: 129,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.238321470508, score_test: 0.230504480636\n",
      "epoch: 130,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.239563901052, score_test: 0.233999815428\n",
      "epoch: 131,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.259499892696, score_test: 0.237360262468\n",
      "epoch: 132,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.246203785461, score_test: 0.283980315054\n",
      "epoch: 133,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.255007164064, score_test: 0.242876450329\n",
      "epoch: 134,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.251477665936, score_test: 0.237364932108\n",
      "epoch: 135,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.245136703671, score_test: 0.241508870299\n",
      "epoch: 136,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.246764846224, score_test: 0.244518087078\n",
      "epoch: 137,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.239778104811, score_test: 0.265695432444\n",
      "epoch: 138,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.242034954931, score_test: 0.252165639738\n",
      "epoch: 139,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.250870316777, score_test: 0.223995235592\n",
      "epoch: 140,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.252549840368, score_test: 0.245176089014\n",
      "epoch: 141,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.24847213404, score_test: 0.255499702664\n",
      "epoch: 142,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.256792259439, score_test: 0.323078967214\n",
      "epoch: 143,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.256996847354, score_test: 0.257900650526\n",
      "epoch: 144,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.247283568584, score_test: 0.230761236482\n",
      "epoch: 145,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.246928187207, score_test: 0.255801645588\n",
      "epoch: 146,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.233256221726, score_test: 0.231058056819\n",
      "epoch: 147,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.247728555255, score_test: 0.225591263855\n",
      "epoch: 148,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.244685062417, score_test: 0.318539616623\n",
      "epoch: 149,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.241127021244, score_test: 0.272522362909\n",
      "epoch: 150,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.257305625679, score_test: 0.228391558441\n",
      "epoch: 151,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.242725272514, score_test: 0.24874631806\n",
      "epoch: 152,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.233519972589, score_test: 0.228376523054\n",
      "epoch: 153,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.241582520683, score_test: 0.242490217691\n",
      "epoch: 154,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.230299703555, score_test: 0.233689298101\n",
      "epoch: 155,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.241240402938, score_test: 0.251023460295\n",
      "epoch: 156,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.258538879289, score_test: 0.24104580024\n",
      "epoch: 157,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.230730964422, score_test: 0.241880961873\n",
      "epoch: 158,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.236578466377, score_test: 0.229301319868\n",
      "epoch: 159,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.231422479419, score_test: 0.241958311464\n",
      "epoch: 160,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.248812544536, score_test: 0.258807845738\n",
      "epoch: 161,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.237777078185, score_test: 0.260466444751\n",
      "epoch: 162,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.241700143415, score_test: 0.230778548311\n",
      "epoch: 163,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.254299950327, score_test: 0.228685170181\n",
      "epoch: 164,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.226999021886, score_test: 0.239776493577\n",
      "epoch: 165,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.242896930785, score_test: 0.242747749532\n",
      "epoch: 166,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.244276100265, score_test: 0.232208911908\n",
      "epoch: 167,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.225463401802, score_test: 0.243341664951\n",
      "epoch: 168,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.221724284448, score_test: 0.222741427398\n",
      "epoch: 169,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.229049105664, score_test: 0.23624958924\n",
      "epoch: 170,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.23154881145, score_test: 0.237137850235\n",
      "epoch: 171,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.221904781766, score_test: 0.212093178021\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 172,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.233357106202, score_test: 0.241432524199\n",
      "epoch: 173,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.236589156953, score_test: 0.257420600039\n",
      "epoch: 174,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.232221119139, score_test: 0.264062993182\n",
      "epoch: 175,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.221828714602, score_test: 0.253230021653\n",
      "epoch: 176,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.236816081791, score_test: 0.229303266946\n",
      "epoch: 177,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.242439964705, score_test: 0.247333239741\n",
      "epoch: 178,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.233951192579, score_test: 0.252502211734\n",
      "epoch: 179,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.225441437914, score_test: 0.37476654397\n",
      "epoch: 180,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.242125324394, score_test: 0.226652233636\n",
      "epoch: 181,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.251970480753, score_test: 0.228555282289\n",
      "epoch: 182,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.232578365095, score_test: 0.22305770459\n",
      "epoch: 183,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.229813210904, score_test: 0.235601534014\n",
      "epoch: 184,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.241284711011, score_test: 0.240219563014\n",
      "epoch: 185,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.232690930181, score_test: 0.24768669385\n",
      "epoch: 186,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.231329485629, score_test: 0.247096380716\n",
      "epoch: 187,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.2248029998, score_test: 0.225329400613\n",
      "epoch: 188,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.240900377391, score_test: 0.296250014248\n",
      "epoch: 189,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.249014598375, score_test: 0.21170690031\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 190,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.225390181534, score_test: 0.258179487973\n",
      "epoch: 191,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.236688954481, score_test: 0.227012420524\n",
      "epoch: 192,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.243747460733, score_test: 0.229275507193\n",
      "epoch: 193,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.225538118827, score_test: 0.224685724362\n",
      "epoch: 194,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.223660569968, score_test: 0.220874998742\n",
      "epoch: 195,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.234285356442, score_test: 0.252676773238\n",
      "epoch: 196,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.227509876381, score_test: 0.206583506422\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 197,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.217535712821, score_test: 0.245678294057\n",
      "epoch: 198,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21963376478, score_test: 0.296928702281\n",
      "epoch: 199,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.229197708336, score_test: 0.235009648207\n",
      "epoch: 200,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.22907029967, score_test: 0.242778374148\n",
      "epoch: 201,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.231701452329, score_test: 0.230349148467\n",
      "epoch: 202,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.227537176242, score_test: 0.24771879249\n",
      "epoch: 203,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.214980371797, score_test: 0.227831232946\n",
      "epoch: 204,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.224260329044, score_test: 0.244367056694\n",
      "epoch: 205,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.227697803507, score_test: 0.238500773641\n",
      "epoch: 206,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.238642835756, score_test: 0.26603478818\n",
      "epoch: 207,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.221358354982, score_test: 0.239472071438\n",
      "epoch: 208,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.228522351929, score_test: 0.27279671388\n",
      "epoch: 209,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.220531110477, score_test: 0.220658934542\n",
      "epoch: 210,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.238088766982, score_test: 0.223410465679\n",
      "epoch: 211,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.224654420911, score_test: 0.235165006718\n",
      "epoch: 212,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.231016019526, score_test: 0.248085569937\n",
      "epoch: 213,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21881320199, score_test: 0.271007053369\n",
      "epoch: 214,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.224214670027, score_test: 0.238247832989\n",
      "epoch: 215,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.216783014411, score_test: 0.242724103471\n",
      "epoch: 216,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207191265613, score_test: 0.252093480888\n",
      "epoch: 217,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.232906566123, score_test: 0.268349677833\n",
      "epoch: 218,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.22736588534, score_test: 0.232549984517\n",
      "epoch: 219,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.223248196295, score_test: 0.252174571434\n",
      "epoch: 220,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.232796135084, score_test: 0.248445342416\n",
      "epoch: 221,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.230206278572, score_test: 0.259148625298\n",
      "epoch: 222,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.216446551029, score_test: 0.231264069156\n",
      "epoch: 223,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.217357877147, score_test: 0.241369501543\n",
      "epoch: 224,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.231554880707, score_test: 0.256322328765\n",
      "epoch: 225,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.228272720201, score_test: 0.244528521153\n",
      "epoch: 226,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.22557329803, score_test: 0.261214054219\n",
      "epoch: 227,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.227236996673, score_test: 0.227848977446\n",
      "epoch: 228,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.217174974535, score_test: 0.234711999849\n",
      "epoch: 229,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.230145970139, score_test: 0.276279628971\n",
      "epoch: 230,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.213912440457, score_test: 0.26147555738\n",
      "epoch: 231,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.225227318132, score_test: 0.230545839144\n",
      "epoch: 232,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.218317416584, score_test: 0.222668177466\n",
      "epoch: 233,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207145071513, score_test: 0.251217896107\n",
      "epoch: 234,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.233575276057, score_test: 0.205544563103\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "epoch: 235,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.221877871023, score_test: 0.232246062539\n",
      "epoch: 236,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.226096112769, score_test: 0.225659856492\n",
      "epoch: 237,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.22594140564, score_test: 0.239910885183\n",
      "epoch: 238,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.217438170266, score_test: 0.244497435989\n",
      "epoch: 239,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.218149039556, score_test: 0.233915424935\n",
      "epoch: 240,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.216480585896, score_test: 0.249830755203\n",
      "epoch: 241,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.222701843536, score_test: 0.237128171468\n",
      "epoch: 242,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21315230871, score_test: 0.238515736362\n",
      "epoch: 243,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.230614681404, score_test: 0.25567491857\n",
      "epoch: 244,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209272987495, score_test: 0.227943730442\n",
      "epoch: 245,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.20970292692, score_test: 0.232090060628\n",
      "epoch: 246,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.217244681319, score_test: 0.263020022801\n",
      "epoch: 247,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.221000849279, score_test: 0.285862962096\n",
      "epoch: 248,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.215815197313, score_test: 0.234917166012\n",
      "epoch: 249,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.224117480564, score_test: 0.232518353123\n",
      "epoch: 250,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.213456482222, score_test: 0.219798929411\n",
      "epoch: 251,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.220142488909, score_test: 0.233219020196\n",
      "epoch: 252,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21456726119, score_test: 0.222266675083\n",
      "epoch: 253,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.205519329279, score_test: 0.230810405721\n",
      "epoch: 254,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.220496758826, score_test: 0.290287338313\n",
      "epoch: 255,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.215292996775, score_test: 0.212865079799\n",
      "epoch: 256,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.223037006743, score_test: 0.282904880573\n",
      "epoch: 257,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.222553382893, score_test: 0.272045365749\n",
      "epoch: 258,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210914502892, score_test: 0.218790700202\n",
      "epoch: 259,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.219346916818, score_test: 0.226237918626\n",
      "epoch: 260,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21533296138, score_test: 0.236877331661\n",
      "epoch: 261,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.230091049815, score_test: 0.222515004785\n",
      "epoch: 262,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.211477443214, score_test: 0.292164682925\n",
      "epoch: 263,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210865216123, score_test: 0.255045869683\n",
      "epoch: 264,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.224583754668, score_test: 0.237028572986\n",
      "epoch: 265,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.213883540776, score_test: 0.226246122982\n",
      "epoch: 266,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.194619731186, score_test: 0.228116649995\n",
      "epoch: 267,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.220436559811, score_test: 0.338215567727\n",
      "epoch: 268,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.250032396947, score_test: 0.280379445055\n",
      "epoch: 269,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.216816554983, score_test: 0.237707870278\n",
      "epoch: 270,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.218225881777, score_test: 0.252466727603\n",
      "epoch: 271,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.229331460064, score_test: 0.212155847249\n",
      "epoch: 272,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.221484731705, score_test: 0.222395797058\n",
      "epoch: 273,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.220195761032, score_test: 0.245209173988\n",
      "epoch: 274,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208530730747, score_test: 0.259798025215\n",
      "epoch: 275,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210605022462, score_test: 0.26894972286\n",
      "epoch: 276,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207926879141, score_test: 0.229239070643\n",
      "epoch: 277,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.219518314446, score_test: 0.295476811759\n",
      "epoch: 278,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.214792544209, score_test: 0.245873980814\n",
      "epoch: 279,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.220385381747, score_test: 0.238899357779\n",
      "epoch: 280,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.198250647745, score_test: 0.228874880965\n",
      "epoch: 281,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21116101494, score_test: 0.236937652944\n",
      "epoch: 282,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.220785243176, score_test: 0.255515703683\n",
      "epoch: 283,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208409922576, score_test: 0.225766727707\n",
      "epoch: 284,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.217898198087, score_test: 0.230689472154\n",
      "epoch: 285,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.2105452813, score_test: 0.227781513046\n",
      "epoch: 286,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209434876455, score_test: 0.247995175653\n",
      "epoch: 287,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.216031422538, score_test: 0.219111389434\n",
      "epoch: 288,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.203490156704, score_test: 0.222607877169\n",
      "epoch: 289,  Current Learning Rate: 3.0e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.215971007706, score_test: 0.251279947076\n",
      "('Upating Current Learning Rate to: ', 0.00015)\n",
      "('Loading the best weights again. best_score: ', 0.20554456310288877)\n",
      "epoch: 290,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.22906785083, score_test: 0.249756616211\n",
      "epoch: 291,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.218635849843, score_test: 0.243910690596\n",
      "epoch: 292,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.211117452285, score_test: 0.22636669416\n",
      "epoch: 293,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.223267391706, score_test: 0.222495707134\n",
      "epoch: 294,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.214851230888, score_test: 0.221206164682\n",
      "epoch: 295,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.219230321655, score_test: 0.206495180136\n",
      "epoch: 296,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.224368813135, score_test: 0.234776760874\n",
      "epoch: 297,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.215934909874, score_test: 0.22924812786\n",
      "epoch: 298,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.20199662765, score_test: 0.232578851977\n",
      "epoch: 299,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210363662589, score_test: 0.220900149079\n",
      "epoch: 300,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21365950538, score_test: 0.215974350246\n",
      "epoch: 301,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.197004528366, score_test: 0.228212117721\n",
      "epoch: 302,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209933095491, score_test: 0.21599390043\n",
      "epoch: 303,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.2094475302, score_test: 0.219785922843\n",
      "epoch: 304,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207536118359, score_test: 0.23128148011\n",
      "epoch: 305,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.23341542432, score_test: 0.225221799687\n",
      "epoch: 306,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.205193680512, score_test: 0.219834828865\n",
      "epoch: 307,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.212953364961, score_test: 0.256952189696\n",
      "epoch: 308,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.211055391833, score_test: 0.235474054626\n",
      "epoch: 309,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.224622124776, score_test: 0.232515053048\n",
      "epoch: 310,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.221419509656, score_test: 0.221183951007\n",
      "epoch: 311,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210415276085, score_test: 0.252953576699\n",
      "epoch: 312,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.205712841448, score_test: 0.219136936845\n",
      "epoch: 313,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21558641518, score_test: 0.22840583653\n",
      "epoch: 314,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210683692518, score_test: 0.2170121186\n",
      "epoch: 315,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.222077363804, score_test: 0.238122666081\n",
      "epoch: 316,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.222702200772, score_test: 0.256827667911\n",
      "epoch: 317,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208781282738, score_test: 0.226974110854\n",
      "epoch: 318,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.217583556308, score_test: 0.231018965798\n",
      "epoch: 319,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.212392896653, score_test: 0.223754680582\n",
      "epoch: 320,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210490887622, score_test: 0.217691664254\n",
      "epoch: 321,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.214123292859, score_test: 0.217905492094\n",
      "epoch: 322,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.198934400921, score_test: 0.230690474709\n",
      "epoch: 323,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.196442527502, score_test: 0.231376455183\n",
      "epoch: 324,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.206394109599, score_test: 0.219073741032\n",
      "epoch: 325,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207362969117, score_test: 0.216146031001\n",
      "epoch: 326,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21181442713, score_test: 0.245692004652\n",
      "epoch: 327,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.216183924445, score_test: 0.223922152176\n",
      "epoch: 328,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208430709169, score_test: 0.214618488822\n",
      "epoch: 329,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.193871223828, score_test: 0.238700424281\n",
      "epoch: 330,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.2057731535, score_test: 0.247016998459\n",
      "epoch: 331,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.204960046175, score_test: 0.26949020725\n",
      "epoch: 332,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.22573298315, score_test: 0.24220728032\n",
      "epoch: 333,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21153152115, score_test: 0.223875065884\n",
      "epoch: 334,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208671124171, score_test: 0.225320293655\n",
      "epoch: 335,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208685303304, score_test: 0.220033496803\n",
      "epoch: 336,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.216854842768, score_test: 0.251360628291\n",
      "epoch: 337,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.228647003674, score_test: 0.243587907531\n",
      "epoch: 338,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.206197470135, score_test: 0.250751260807\n",
      "epoch: 339,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207822679953, score_test: 0.214164648222\n",
      "epoch: 340,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.203034538861, score_test: 0.23506287335\n",
      "epoch: 341,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.216140722999, score_test: 0.26672881004\n",
      "epoch: 342,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.211040691089, score_test: 0.23768033815\n",
      "epoch: 343,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207586715638, score_test: 0.223492059035\n",
      "epoch: 344,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.218763842477, score_test: 0.231859563231\n",
      "epoch: 345,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.20182634778, score_test: 0.225798663955\n",
      "epoch: 346,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209624199185, score_test: 0.2247957278\n",
      "epoch: 347,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208814943884, score_test: 0.242245515103\n",
      "epoch: 348,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207184804952, score_test: 0.224845893843\n",
      "epoch: 349,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209756998845, score_test: 0.233302428636\n",
      "epoch: 350,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.190422197142, score_test: 0.231668834106\n",
      "epoch: 351,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209450195977, score_test: 0.209739471872\n",
      "epoch: 352,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.204650078751, score_test: 0.222594662807\n",
      "epoch: 353,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.200479250502, score_test: 0.236593205088\n",
      "epoch: 354,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.222920615187, score_test: 0.220125781476\n",
      "epoch: 355,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.194157245677, score_test: 0.2529328291\n",
      "epoch: 356,  Current Learning Rate: 1.5e-04\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.200283071717, score_test: 0.259887526124\n",
      "('Upating Current Learning Rate to: ', 7.5e-05)\n",
      "('Loading the best weights again. best_score: ', 0.20554456310288877)\n",
      "epoch: 357,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.223777464113, score_test: 0.218627697713\n",
      "epoch: 358,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.212814723318, score_test: 0.218285258894\n",
      "epoch: 359,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209669708132, score_test: 0.224165559706\n",
      "epoch: 360,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.215706666584, score_test: 0.229743125808\n",
      "epoch: 361,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.203624642136, score_test: 0.218391613468\n",
      "epoch: 362,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.205960878876, score_test: 0.229650741269\n",
      "epoch: 363,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.214736594924, score_test: 0.223386474266\n",
      "epoch: 364,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.222027194424, score_test: 0.22745052599\n",
      "epoch: 365,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210147760106, score_test: 0.22900056419\n",
      "epoch: 366,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.206576361209, score_test: 0.229776201145\n",
      "epoch: 367,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207991923957, score_test: 0.222913353444\n",
      "epoch: 368,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.206115527444, score_test: 0.236602678988\n",
      "epoch: 369,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.20486739682, score_test: 0.226772213482\n",
      "epoch: 370,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208772062024, score_test: 0.237505655944\n",
      "epoch: 371,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.219265254066, score_test: 0.231224088959\n",
      "epoch: 372,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.218073909388, score_test: 0.239347662152\n",
      "epoch: 373,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.218493977522, score_test: 0.236802170481\n",
      "epoch: 374,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208930195101, score_test: 0.235458135559\n",
      "epoch: 375,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.204961764321, score_test: 0.225310302889\n",
      "epoch: 376,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.206681760417, score_test: 0.23013506802\n",
      "epoch: 377,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210349416587, score_test: 0.226653581763\n",
      "epoch: 378,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.211446356311, score_test: 0.243074191491\n",
      "epoch: 379,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.20014455741, score_test: 0.235941887631\n",
      "epoch: 380,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.212971575605, score_test: 0.233490586373\n",
      "epoch: 381,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.205665653477, score_test: 0.225270915001\n",
      "epoch: 382,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208300716189, score_test: 0.235952217294\n",
      "epoch: 383,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.220640404736, score_test: 0.233663624719\n",
      "epoch: 384,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209693113963, score_test: 0.223887931417\n",
      "epoch: 385,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207120127609, score_test: 0.228426395574\n",
      "epoch: 386,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.206232150974, score_test: 0.235412245188\n",
      "epoch: 387,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21500441225, score_test: 0.237686506802\n",
      "epoch: 388,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.20431073168, score_test: 0.235551013177\n",
      "epoch: 389,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209743174001, score_test: 0.233890965673\n",
      "epoch: 390,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.220998528569, score_test: 0.247919692988\n",
      "epoch: 391,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.219496438469, score_test: 0.239521882595\n",
      "epoch: 392,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.212434252857, score_test: 0.235026295094\n",
      "epoch: 393,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.222941882015, score_test: 0.239694856801\n",
      "epoch: 394,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.215182848528, score_test: 0.240136278192\n",
      "epoch: 395,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.205581285963, score_test: 0.234027605562\n",
      "epoch: 396,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.204395984305, score_test: 0.226606369528\n",
      "epoch: 397,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.200877453485, score_test: 0.224186893182\n",
      "epoch: 398,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209989956825, score_test: 0.224823032708\n",
      "epoch: 399,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.197753473001, score_test: 0.217477275336\n",
      "epoch: 400,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.214536157122, score_test: 0.246821638474\n",
      "epoch: 401,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207369008503, score_test: 0.254011402635\n",
      "epoch: 402,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210109334271, score_test: 0.221269461378\n",
      "epoch: 403,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.220353501874, score_test: 0.237969819225\n",
      "epoch: 404,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.215546861719, score_test: 0.229180967354\n",
      "epoch: 405,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.210084809583, score_test: 0.232750340486\n",
      "epoch: 406,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.2142276327, score_test: 0.227360002511\n",
      "epoch: 407,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.211212998368, score_test: 0.230114260203\n",
      "epoch: 408,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207283553935, score_test: 0.229021399114\n",
      "epoch: 409,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.197119780679, score_test: 0.232151672152\n",
      "epoch: 410,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209720276838, score_test: 0.234298642597\n",
      "epoch: 411,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.203500543784, score_test: 0.231480021307\n",
      "epoch: 412,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.202694124508, score_test: 0.237720952456\n",
      "epoch: 413,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21970628764, score_test: 0.246279867493\n",
      "epoch: 414,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.206850667691, score_test: 0.234936411799\n",
      "epoch: 415,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.212433061275, score_test: 0.226672157217\n",
      "epoch: 416,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.206878993869, score_test: 0.230998942038\n",
      "epoch: 417,  Current Learning Rate: 7.5e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.219510286346, score_test: 0.241942049693\n",
      "('Upating Current Learning Rate to: ', 3.75e-05)\n",
      "('Loading the best weights again. best_score: ', 0.20554456310288877)\n",
      "epoch: 418,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.223253117478, score_test: 0.219887654187\n",
      "epoch: 419,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.221448163315, score_test: 0.230135940177\n",
      "epoch: 420,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.228775558024, score_test: 0.224805531642\n",
      "epoch: 421,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207200498372, score_test: 0.221365255159\n",
      "epoch: 422,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.227665387357, score_test: 0.232871100746\n",
      "epoch: 423,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.212793226983, score_test: 0.222036164532\n",
      "epoch: 424,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21965221502, score_test: 0.224329743048\n",
      "epoch: 425,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.212211944909, score_test: 0.227031849116\n",
      "epoch: 426,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.213836025542, score_test: 0.226316741835\n",
      "epoch: 427,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.217255814779, score_test: 0.229376129066\n",
      "epoch: 428,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208497336649, score_test: 0.224768796739\n",
      "epoch: 429,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.215583974889, score_test: 0.228278600674\n",
      "epoch: 430,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.214951673235, score_test: 0.222175068933\n",
      "epoch: 431,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.217081792079, score_test: 0.232780953279\n",
      "epoch: 432,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.201977575052, score_test: 0.222963418488\n",
      "epoch: 433,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208920881968, score_test: 0.224151370735\n",
      "epoch: 434,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.219083229876, score_test: 0.21921685028\n",
      "epoch: 435,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.20469856004, score_test: 0.223644677688\n",
      "epoch: 436,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.203635831251, score_test: 0.229298944452\n",
      "epoch: 437,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.224474999509, score_test: 0.228375635787\n",
      "epoch: 438,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.218027448662, score_test: 0.22560718172\n",
      "epoch: 439,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.207722333519, score_test: 0.236970326221\n",
      "epoch: 440,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.204574325662, score_test: 0.223031376517\n",
      "epoch: 441,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.206517454136, score_test: 0.219805912653\n",
      "epoch: 442,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21093467607, score_test: 0.223869267897\n",
      "epoch: 443,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.214740004316, score_test: 0.223413370388\n",
      "epoch: 444,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.214207788577, score_test: 0.21878537044\n",
      "epoch: 445,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.200632155014, score_test: 0.228000279539\n",
      "epoch: 446,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.215584349499, score_test: 0.221664871257\n",
      "epoch: 447,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209361055805, score_test: 0.226066932244\n",
      "epoch: 448,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.217442603241, score_test: 0.221923365113\n",
      "epoch: 449,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.212196119837, score_test: 0.219202050488\n",
      "epoch: 450,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.20888914457, score_test: 0.224984933963\n",
      "epoch: 451,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.205755565504, score_test: 0.220585008458\n",
      "epoch: 452,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.208131852451, score_test: 0.223776928525\n",
      "epoch: 453,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.204061350679, score_test: 0.219287613175\n",
      "epoch: 454,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.21620272313, score_test: 0.22255650364\n",
      "epoch: 455,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.203922712805, score_test: 0.22179478865\n",
      "epoch: 456,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.193818232348, score_test: 0.217341049291\n",
      "epoch: 457,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.20375566863, score_test: 0.220895832081\n",
      "epoch: 458,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.211734862053, score_test: 0.218884011511\n",
      "epoch: 459,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.209540330447, score_test: 0.228287741449\n",
      "epoch: 460,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.211638125747, score_test: 0.229196636874\n",
      "epoch: 461,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.219157435367, score_test: 0.222273683152\n",
      "epoch: 462,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.194866293805, score_test: 0.223940578607\n",
      "epoch: 463,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.202219378122, score_test: 0.230518592151\n",
      "epoch: 464,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.200095668873, score_test: 0.241783859081\n",
      "epoch: 465,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.214148049181, score_test: 0.234534577044\n",
      "epoch: 466,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.20434181527, score_test: 0.224600485833\n",
      "epoch: 467,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.212900166761, score_test: 0.224274862407\n",
      "epoch: 468,  Current Learning Rate: 3.8e-05\n",
      "no normalization!\n",
      "no normalization!\n",
      "score_train: 0.204224138718, score_test: 0.226329428647\n",
      "epoch: 469,  Current Learning Rate: 3.8e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-218bff7e9969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# train test on fold #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mtrain_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# loading best weights from training session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-35eb6260e5e7>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[0;34m(X_train, y_train, X_test, y_test, params_train)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mbatches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#batch_size*10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0mX_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mhist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mra/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mra/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mrandom_transform\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mtransform_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_matrix_offset_center\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         x = apply_transform(x, transform_matrix, img_channel_index,\n\u001b[0;32m--> 362\u001b[0;31m                             fill_mode=self.fill_mode, cval=self.cval)\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_shift_range\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_channel_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_shift_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_channel_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mra/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(x, transform_matrix, channel_index, fill_mode, cval)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mfinal_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n\u001b[0;32m--> 108\u001b[0;31m                       final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mra/anaconda2/lib/python2.7/site-packages/scipy/ndimage/interpolation.pyc\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         _geometric_transform(filtered, None, None, matrix, offset,\n\u001b[0;32m--> 438\u001b[0;31m                              output, order, mode, cval, None, None)\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mra/anaconda2/lib/python2.7/site-packages/scipy/ndimage/interpolation.pyc\u001b[0m in \u001b[0;36m_geometric_transform\u001b[0;34m(input, mapping, coordinates, matrix, offset, output, order, mode, cval, extra_arguments, extra_keywords)\u001b[0m\n\u001b[1;32m    130\u001b[0m     _nd_image.geometric_transform(\n\u001b[1;32m    131\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         order, mode, cval, extra_arguments, extra_keywords)\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_folds=5\n",
    "#skf = StratifiedKFold(n_splits=n_folds,random_state=123,shuffle=True)\n",
    "#skf = KFold(n_splits=n_folds,random_state=234)\n",
    "skf = ShuffleSplit(n_splits=n_folds, test_size=0.1, random_state=321)\n",
    "\n",
    "# loop over folds\n",
    "foldnm=0\n",
    "scores_nfolds=[]\n",
    "\n",
    "print ('wait ...')\n",
    "for train_ind, test_ind in skf.split(X,y):\n",
    "    foldnm+=1    \n",
    "    print('fold %s' %foldnm)\n",
    "\n",
    "    train_ind=list(np.sort(train_ind))\n",
    "    test_ind=list(np.sort(test_ind))\n",
    "    #print test_ind\n",
    "\n",
    "    X_train,y_train=X[train_ind],y[train_ind]       \n",
    "    X_test,y_test=X[test_ind],y[test_ind] \n",
    "    \n",
    "    \n",
    "    array_stats(X_train)\n",
    "    array_stats(y_train)\n",
    "    array_stats(X_test)\n",
    "    array_stats(y_test)\n",
    "    print ('-'*30)\n",
    "    \n",
    "    # exeriment name to record weights and scores\n",
    "    netinfo='trainTest10'\n",
    "    experiment=netinfo+'_hw_'+str(h)+'by'+str(w)+'_initfilts_'+str(params_train['init_filters'])\n",
    "    print ('experiment: %s' %experiment)\n",
    "\n",
    "    # checkpoint\n",
    "    weightfolder='./output/weights/'+experiment+'/fold'+str(foldnm)\n",
    "    if  not os.path.exists(weightfolder):\n",
    "        os.makedirs(weightfolder)\n",
    "    print ('weights folder created')    \n",
    "    \n",
    "    # path to weights\n",
    "    path2weights=weightfolder+\"/weights.hdf5\"\n",
    "    path2model=weightfolder+\"/model.hdf5\"    \n",
    "    \n",
    "   # training params\n",
    "    params_train['foldnm']=foldnm\n",
    "    params_train['learning_rate']=3e-4\n",
    "    params_train['path2weights']=path2weights\n",
    "    model=modelCnn(params_train)\n",
    "    #model.summary()\n",
    "\n",
    "    \n",
    "    # train test on fold #\n",
    "    train_test_model(X_train,y_train,X_test,y_test,params_train)\n",
    "    \n",
    "    # loading best weights from training session\n",
    "    if  os.path.exists(path2weights):\n",
    "        model.load_weights(path2weights)\n",
    "        print ('%s loaded!' %path2weights)\n",
    "    else:\n",
    "        raise IOError('weights does not exist!!!')\n",
    "\n",
    "    score_test=model.evaluate(preprocess(X_test,norm_type),y_test,verbose=0)\n",
    "    print ('score_test: %.5f' %(score_test))    \n",
    "    print ('-' *30)\n",
    "    # store scores for all folds\n",
    "    scores_nfolds.append(score_test)\n",
    "\n",
    "print ('average score for %s folds is %s' %(n_folds,np.mean(scores_nfolds)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading leaderboard data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# leaderboard\n",
    "learder = pd.read_json('../data/test.json')\n",
    "X_lb = get_images(learder )\n",
    "array_stats(X_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction for nfolds\n",
    "y_pred=[]\n",
    "for foldnm in range(1,n_folds+1):\n",
    "    \n",
    "    # load weights\n",
    "    experiment=netinfo+'_hw_'+str(h)+'by'+str(w)+'_initfilts_'+str(params_train['init_filters'])\n",
    "    print ('experiment:', experiment)\n",
    "    weightfolder='./output/weights/'+experiment+'/fold'+str(foldnm)\n",
    "    # path to weights\n",
    "    path2weights=weightfolder+\"/weights.hdf5\"\n",
    "    if  os.path.exists(path2weights):\n",
    "        model.load_weights(path2weights)\n",
    "        print ('%s loaded!' %path2weights)\n",
    "    else:\n",
    "        raise IOError ('weights does not exist!')\n",
    "\n",
    "    # prediction\n",
    "    y_pred_perfold=model.predict(preprocess(X_lb,norm_type))\n",
    "    print y_pred_perfold.shape    \n",
    "    y_pred.append(y_pred_perfold)        \n",
    "        \n",
    "# reshape \n",
    "y_pred1=np.array(y_pred)\n",
    "y_pred2=np.mean(y_pred1,axis=0)\n",
    "\n",
    "r1,c1=y_pred2.shape\n",
    "print y_pred2[0:5]\n",
    "print (r1,c1)\n",
    "pred=np.reshape(y_pred2,(r1*c1,1))[:,0]\n",
    "print (pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submissionFolder='./output/submissions'\n",
    "if not os.path.exists(submissionFolder):\n",
    "        os.mkdir(submissionFolder)\n",
    "\n",
    "        \n",
    "submission = pd.DataFrame({'id': learder['id'], 'is_iceberg': pred})\n",
    "now = datetime.datetime.now()\n",
    "info=experiment\n",
    "suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "path2submission = os.path.join('./output/submissions', 'submission_' + suffix + '.csv')\n",
    "print (path2submission)\n",
    "submission.to_csv(path2submission, index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
